{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/f6xjtlr526zbr86__yns243m0000gn/T/ipykernel_78664/2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Book-Crossing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/f6xjtlr526zbr86__yns243m0000gn/T/ipykernel_78664/3698374196.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/Book crossing /BX-Books.csv', sep=';',on_bad_lines = 'skip', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "# Reading the CSV files and skipping the bad lines\n",
    "books = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/Book crossing /BX-Books.csv', sep=';',on_bad_lines = 'skip', encoding='latin-1')\n",
    "ratings = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/Book crossing /BX-Book-Ratings.csv', sep=';',on_bad_lines = 'skip', encoding='latin-1')\n",
    "users = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/Book crossing /BX-Users.csv',sep=';',on_bad_lines = 'skip', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Books Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "books.rename(columns={'Book-Title': 'Title', 'Book-Author': 'Author', 'Year-Of-Publication': 'Year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the URL columns for the Books table\n",
    "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['Author'].isnull(), 'Author'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['Publisher'].isnull(), 'Publisher'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.at[209538, 'Publisher'] = 'DK Publishing Inc'\n",
    "books.at[209538, 'Year'] = 2000\n",
    "books.at[209538, 'Title'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
    "books.at[209538, 'Author'] = 'Michael Teitelbaum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.at[221678, 'Publisher'] = 'DK Publishing Inc'\n",
    "books.at[221678, 'Year'] = 2000\n",
    "books.at[221678, 'Title'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
    "books.at[221678, 'Author'] = 'James Buckley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.at[220731, 'Publisher'] = 'Gallimard'\n",
    "books.at[220731, 'Year'] = 2003\n",
    "books.at[220731, 'Title'] = 'Peuple du ciel - Suivi de Les bergers '\n",
    "books.at[220731, 'Author'] = 'Jean-Marie Gustave Le ClÃ?Â©zio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting year to integer values\n",
    "books['Year'] = pd.to_numeric(books['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = books['Year'].value_counts()\n",
    "most_commen_year = count[count == count.max()].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing all values for Publishing years greater than 2004 or equal to 0 with the maximum year\n",
    "books.loc[books['Year'] > 2004, 'Year'] = most_commen_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['Year'] == 0, 'Year'] = most_commen_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Users Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "users.rename(columns={'User-ID': 'UserID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ages that have values nan, less than 8, and more than 90 are invalid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_range = users[users['Age'] <= 90] \n",
    "age_range = age_range[age_range['Age'] >= 8]\n",
    "mean = age_range['Age'].mean().round()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[(users['Age'] > 90) | (users['Age'] < 8),'Age'] = mean\n",
    "users['Age']=users['Age'].fillna(mean).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ratings Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "ratings.rename(columns={'User-ID': 'UserID', 'Book-Rating': 'BookRating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop([\"UserID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN         BookRating\n",
       " 0330299891  3.0           1\n",
       "0875961096   0.0           1\n",
       "0875961010   0.0           1\n",
       "087595247X   0.0           1\n",
       "0875952372   10.0          1\n",
       "                          ..\n",
       "0451124847   0.0           1\n",
       "0451124693   0.0           1\n",
       "0451124685   2.0           1\n",
       "0451124634   0.0           1\n",
       "Ô½crosoft    7.0           1\n",
       "Name: count, Length: 340556, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_userrate = ratings.groupby(['ISBN'], as_index=False)['BookRating'].mean().round(0)\n",
    "bx_userrate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 3., 5., 4.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the ratings to from a scale of 1-10 to 1-5\n",
    "scaled_ratings = (bx_userrate['BookRating'] - 1) * (5 / 9) + 1\n",
    "bx_userrate['Scaled Rating'] = np.clip(round(scaled_ratings), 1, 5)\n",
    "bx_userrate['Scaled Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>BookRating</th>\n",
       "      <th>Scaled Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0330299891</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0375404120</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0586045007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9022906116</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9032803328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN  BookRating  Scaled Rating\n",
       "0   0330299891         3.0              2\n",
       "1   0375404120         2.0              2\n",
       "2   0586045007         0.0              1\n",
       "3   9022906116         4.0              3\n",
       "4   9032803328         0.0              1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_userrate['Scaled Rating'] = bx_userrate['Scaled Rating'].astype(int)\n",
    "bx_userrate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Merging Books, Users, and Ratings tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = pd.merge(books, bx_userrate, on='ISBN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Goodbooks-10k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbooks = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/goodreads-10k/books.csv', sep=',',on_bad_lines = 'skip', encoding='latin-1')\n",
    "goodratings = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/goodreads-10k/ratings.csv', sep=',',on_bad_lines = 'skip', encoding='latin-1')\n",
    "goodbooks_tags = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/goodreads-10k/book_tags.csv',sep=',',on_bad_lines = 'skip', encoding='latin-1')\n",
    "goodtags = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/goodreads-10k/tags.csv',sep=',',on_bad_lines = 'skip', encoding='latin-1')\n",
    "good_toread = pd.read_csv('/Users/sanjeevani1109/Desktop/Book_Recommendation_System/goodreads-10k/to_read.csv',sep=',',on_bad_lines = 'skip', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Books Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the URL columns for the Books table\n",
    "goodbooks.drop(['image_url', 'small_image_url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "goodbooks.rename(columns={'book_id': 'BookID', 'isbn': 'ISBN', 'authors': 'Author', 'original_publication_year': 'Year', 'original_title': 'Title', 'average_rating': 'Avgrating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1994.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_year = goodbooks.loc[goodbooks['Year'] >= 1800, 'Year'].mean().round()\n",
    "average_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbooks.loc[goodbooks['Year'] == 0, 'Year'] = average_year\n",
    "goodbooks.loc[:, 'Year'] = goodbooks['Year'].fillna(average_year)\n",
    "goodbooks.loc[goodbooks['Year'] < 1800, 'Year'] = average_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbooks.dropna(subset=['Title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9415, 21)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodbooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbooks['Year'] = goodbooks['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new data frame only with the relevant columns\n",
    "selected_cols = ['id', 'BookID', 'Author', 'Year', 'Title', 'Avgrating', 'ratings_count']\n",
    "new_goodbooks = goodbooks[selected_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9415, 7)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_goodbooks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Ratings Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "goodratings.rename(columns={'book_id': 'BookID', 'user_id': 'UserID', 'rating': 'Rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BookID  Rating\n",
       "1       4.0       1\n",
       "6671    4.0       1\n",
       "6664    4.0       1\n",
       "6665    4.0       1\n",
       "6666    4.0       1\n",
       "                 ..\n",
       "3334    4.0       1\n",
       "3335    4.0       1\n",
       "3336    4.0       1\n",
       "3337    4.0       1\n",
       "10000   4.0       1\n",
       "Name: count, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rate = goodratings.groupby(['BookID'], as_index=False)['Rating'].mean().round(0)\n",
    "\n",
    "user_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BookID  Mean Rating\n",
       "1       4.0            1\n",
       "6671    4.0            1\n",
       "6664    4.0            1\n",
       "6665    4.0            1\n",
       "6666    4.0            1\n",
       "                      ..\n",
       "3334    4.0            1\n",
       "3335    4.0            1\n",
       "3336    4.0            1\n",
       "3337    4.0            1\n",
       "10000   4.0            1\n",
       "Name: count, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming the columns\n",
    "user_rate.rename(columns={'Rating': 'Mean Rating'}, inplace=True)\n",
    "\n",
    "user_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rate['Mean Rating'] = user_rate['Mean Rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Merging the Books and Ratings tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BookID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Avgrating</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>7130616</td>\n",
       "      <td>Ilona Andrews</td>\n",
       "      <td>2010</td>\n",
       "      <td>Bayou Moon</td>\n",
       "      <td>4.09</td>\n",
       "      <td>17204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>208324</td>\n",
       "      <td>Robert A. Caro</td>\n",
       "      <td>1990</td>\n",
       "      <td>Means of Ascent</td>\n",
       "      <td>4.25</td>\n",
       "      <td>12582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>77431</td>\n",
       "      <td>Patrick O'Brian</td>\n",
       "      <td>1977</td>\n",
       "      <td>The Mauritius Command</td>\n",
       "      <td>4.35</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>8565083</td>\n",
       "      <td>Peggy Orenstein</td>\n",
       "      <td>2011</td>\n",
       "      <td>Cinderella Ate My Daughter: Dispatches from th...</td>\n",
       "      <td>3.65</td>\n",
       "      <td>11279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>8914</td>\n",
       "      <td>John Keegan</td>\n",
       "      <td>1998</td>\n",
       "      <td>The First World War</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9415 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   BookID                        Author  Year  \\\n",
       "0         1  2767052               Suzanne Collins  2008   \n",
       "1         2        3  J.K. Rowling, Mary GrandPrÃ©  1997   \n",
       "2         3    41865               Stephenie Meyer  2005   \n",
       "3         4     2657                    Harper Lee  1960   \n",
       "4         5     4671           F. Scott Fitzgerald  1925   \n",
       "...     ...      ...                           ...   ...   \n",
       "9995   9996  7130616                 Ilona Andrews  2010   \n",
       "9996   9997   208324                Robert A. Caro  1990   \n",
       "9997   9998    77431               Patrick O'Brian  1977   \n",
       "9998   9999  8565083               Peggy Orenstein  2011   \n",
       "9999  10000     8914                   John Keegan  1998   \n",
       "\n",
       "                                                  Title  Avgrating  \\\n",
       "0                                      The Hunger Games       4.34   \n",
       "1              Harry Potter and the Philosopher's Stone       4.44   \n",
       "2                                              Twilight       3.57   \n",
       "3                                 To Kill a Mockingbird       4.25   \n",
       "4                                      The Great Gatsby       3.89   \n",
       "...                                                 ...        ...   \n",
       "9995                                         Bayou Moon       4.09   \n",
       "9996                                   Means of Ascent        4.25   \n",
       "9997                              The Mauritius Command       4.35   \n",
       "9998  Cinderella Ate My Daughter: Dispatches from th...       3.65   \n",
       "9999                                The First World War       4.00   \n",
       "\n",
       "      ratings_count  \n",
       "0           4780653  \n",
       "1           4602479  \n",
       "2           3866839  \n",
       "3           3198671  \n",
       "4           2683664  \n",
       "...             ...  \n",
       "9995          17204  \n",
       "9996          12582  \n",
       "9997           9421  \n",
       "9998          11279  \n",
       "9999           9162  \n",
       "\n",
       "[9415 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_goodbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rate = user_rate.rename(columns={\"BookID\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Mean Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Mean Rating\n",
       "0   1            4\n",
       "1   2            4\n",
       "2   3            3\n",
       "3   4            4\n",
       "4   5            4"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbx = pd.merge(new_goodbooks, user_rate, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9415, 8)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BookID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Avgrating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>Mean Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   BookID                        Author  Year  \\\n",
       "0   1  2767052               Suzanne Collins  2008   \n",
       "1   2        3  J.K. Rowling, Mary GrandPrÃ©  1997   \n",
       "2   3    41865               Stephenie Meyer  2005   \n",
       "3   4     2657                    Harper Lee  1960   \n",
       "4   5     4671           F. Scott Fitzgerald  1925   \n",
       "\n",
       "                                      Title  Avgrating  ratings_count  \\\n",
       "0                          The Hunger Games       4.34        4780653   \n",
       "1  Harry Potter and the Philosopher's Stone       4.44        4602479   \n",
       "2                                  Twilight       3.57        3866839   \n",
       "3                     To Kill a Mockingbird       4.25        3198671   \n",
       "4                          The Great Gatsby       3.89        2683664   \n",
       "\n",
       "   Mean Rating  \n",
       "0            4  \n",
       "1            4  \n",
       "2            3  \n",
       "3            4  \n",
       "4            4  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk #using the nltk library for tokenization and lemmatization\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean text data\n",
    "def clean_text(text):\n",
    "    text = text.lower()     #Converting the text to lowercase\n",
    "    text = re.sub(r'\\d+', ' ', text)    # Removing digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Removing special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))    #Removing punctuation     \n",
    "    tokens = word_tokenize(text) #Tokenization of the text\n",
    "    non_stopwords = []  #Creating an empty list to store the non-stopwords\n",
    "    stop_words = set(stopwords.words('english')) #Initializing the NLTK English stopwords\n",
    "    #Lemmatization of the words/tokens\n",
    "    lemmatizer = WordNetLemmatizer()    #Initialization of the NLTK WordNet Lemmatizer\n",
    "\n",
    "    #Iterating through the list of tokens, lemmatizing them, and adding it to the list of non-stopwords\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            lemma = lemmatizer.lemmatize(token) #Performing lemmatization\n",
    "            non_stopwords.append(lemma)  # Appending the stemmed token back to the list of non-stopwords\n",
    "\n",
    "    # Joining the tokens/words from the list of non-stopwords into a string\n",
    "    filtered_text = ' '.join(non_stopwords)\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the text_clean function to the 'Title' column of the first data frame 'bx' i.e., the Book Crossing dataset's final data frame\n",
    "bx['cleaned_title'] = bx['Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame - bx:\n",
      "                                               Title  \\\n",
      "0                                Classical Mythology   \n",
      "1                                       Clara Callan   \n",
      "2                               Decision in Normandy   \n",
      "3  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4                             The Mummies of Urumchi   \n",
      "\n",
      "                                       cleaned_title  \n",
      "0                                classical mythology  \n",
      "1                                       clara callan  \n",
      "2                                  decision normandy  \n",
      "3  flu story great influenza pandemic search viru...  \n",
      "4                                      mummy urumchi  \n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the cleaned column for the first DataFrame 'bx'\n",
    "print(\"First DataFrame - bx:\")\n",
    "print(bx[['Title', 'cleaned_title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the text_clean function to the 'Title' column of the second data frame 'gbx' i.e., the Goodbooks-10k dataset's final data frame\n",
    "gbx['cleaned_title'] = gbx['Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second DataFrame - gbx:\n",
      "                                      Title                   cleaned_title\n",
      "0                          The Hunger Games                     hunger game\n",
      "1  Harry Potter and the Philosopher's Stone  harry potter philosopher stone\n",
      "2                                  Twilight                        twilight\n",
      "3                     To Kill a Mockingbird                kill mockingbird\n",
      "4                          The Great Gatsby                    great gatsby\n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the cleaned column for the second DataFrame 'gbx'\n",
    "print(\"\\nSecond DataFrame - gbx:\")\n",
    "print(gbx[['Title', 'cleaned_title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 'Author' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_text function to the 'Author' column of the first data frame 'bx'\n",
    "bx['cleaned_author'] = bx['Author'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame - bx:\n",
      "                 Author        cleaned_author\n",
      "0    Mark P. O. Morford        mark p morford\n",
      "1  Richard Bruce Wright  richard bruce wright\n",
      "2          Carlo D'Este           carlo deste\n",
      "3      Gina Bari Kolata      gina bari kolata\n",
      "4       E. J. W. Barber          e j w barber\n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the cleaned column for the first DataFrame 'bx'\n",
    "print(\"First DataFrame - bx:\")\n",
    "print(bx[['Author', 'cleaned_author']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_text function to the 'Author' column of the second data frame 'gbx'\n",
    "gbx['cleaned_author'] = gbx['Author'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second DataFrame - gbx:\n",
      "                         Author           cleaned_author\n",
      "0               Suzanne Collins          suzanne collins\n",
      "1  J.K. Rowling, Mary GrandPrÃ©  jk rowling mary grandpr\n",
      "2               Stephenie Meyer          stephenie meyer\n",
      "3                    Harper Lee               harper lee\n",
      "4           F. Scott Fitzgerald       f scott fitzgerald\n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the cleaned column for the second DataFrame 'gbx'\n",
    "print(\"\\nSecond DataFrame - gbx:\")\n",
    "print(gbx[['Author', 'cleaned_author']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Scaled Rating</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_author</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>classical mythology</td>\n",
       "      <td>mark p morford</td>\n",
       "      <td>classical mythology mark p morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>clara callan richard bruce wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>decision normandy</td>\n",
       "      <td>carlo deste</td>\n",
       "      <td>decision normandy carlo deste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>flu story great influenza pandemic search viru...</td>\n",
       "      <td>gina bari kolata</td>\n",
       "      <td>flu story great influenza pandemic search viru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>mummy urumchi</td>\n",
       "      <td>e j w barber</td>\n",
       "      <td>mummy urumchi e j w barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                Author  \\\n",
       "0                                Classical Mythology    Mark P. O. Morford   \n",
       "1                                       Clara Callan  Richard Bruce Wright   \n",
       "2                               Decision in Normandy          Carlo D'Este   \n",
       "3  Flu: The Story of the Great Influenza Pandemic...      Gina Bari Kolata   \n",
       "4                             The Mummies of Urumchi       E. J. W. Barber   \n",
       "\n",
       "   Year  Scaled Rating                                      cleaned_title  \\\n",
       "0  2002              1                                classical mythology   \n",
       "1  2001              3                                       clara callan   \n",
       "2  1991              3                                  decision normandy   \n",
       "3  1999              3  flu story great influenza pandemic search viru...   \n",
       "4  1999              1                                      mummy urumchi   \n",
       "\n",
       "         cleaned_author                                           combined  \n",
       "0        mark p morford                 classical mythology mark p morford  \n",
       "1  richard bruce wright                  clara callan richard bruce wright  \n",
       "2           carlo deste                      decision normandy carlo deste  \n",
       "3      gina bari kolata  flu story great influenza pandemic search viru...  \n",
       "4          e j w barber                         mummy urumchi e j w barber  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "bxcolumns_to_copy = ['ISBN', 'Publisher', 'BookRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ISBN', 'Publisher', 'BookRating'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb Cell 74\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb#Y354sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bx\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49mbxcolumns_to_copy, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb#Y354sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m bx\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5421\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5422\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5430\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5431\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5432\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5433\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5569\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5570\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5571\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5572\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5573\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5574\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5575\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5576\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py:4782\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4781\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4782\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4784\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py:4824\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4822\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4823\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4824\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4825\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4827\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4828\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py:7069\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7067\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   7068\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 7069\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7070\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   7071\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ISBN', 'Publisher', 'BookRating'] not found in axis\""
     ]
    }
   ],
   "source": [
    "bx.drop(columns=bxcolumns_to_copy, inplace=True)\n",
    "bx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BookID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Avgrating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4</td>\n",
       "      <td>hunger game</td>\n",
       "      <td>suzanne collins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4</td>\n",
       "      <td>harry potter philosopher stone</td>\n",
       "      <td>jk rowling mary grandpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3</td>\n",
       "      <td>twilight</td>\n",
       "      <td>stephenie meyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "      <td>4</td>\n",
       "      <td>kill mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "      <td>4</td>\n",
       "      <td>great gatsby</td>\n",
       "      <td>f scott fitzgerald</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   BookID                        Author  Year  \\\n",
       "0   1  2767052               Suzanne Collins  2008   \n",
       "1   2        3  J.K. Rowling, Mary GrandPrÃ©  1997   \n",
       "2   3    41865               Stephenie Meyer  2005   \n",
       "3   4     2657                    Harper Lee  1960   \n",
       "4   5     4671           F. Scott Fitzgerald  1925   \n",
       "\n",
       "                                      Title  Avgrating  ratings_count  \\\n",
       "0                          The Hunger Games       4.34        4780653   \n",
       "1  Harry Potter and the Philosopher's Stone       4.44        4602479   \n",
       "2                                  Twilight       3.57        3866839   \n",
       "3                     To Kill a Mockingbird       4.25        3198671   \n",
       "4                          The Great Gatsby       3.89        2683664   \n",
       "\n",
       "   Mean Rating                   cleaned_title           cleaned_author  \n",
       "0            4                     hunger game          suzanne collins  \n",
       "1            4  harry potter philosopher stone  jk rowling mary grandpr  \n",
       "2            3                        twilight          stephenie meyer  \n",
       "3            4                kill mockingbird               harper lee  \n",
       "4            4                    great gatsby       f scott fitzgerald  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "newgbxcolumns_to_copy = ['id','BookID', 'Avgrating', 'ratings_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>4</td>\n",
       "      <td>hunger game</td>\n",
       "      <td>suzanne collins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>4</td>\n",
       "      <td>harry potter philosopher stone</td>\n",
       "      <td>jk rowling mary grandpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>3</td>\n",
       "      <td>twilight</td>\n",
       "      <td>stephenie meyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4</td>\n",
       "      <td>kill mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>4</td>\n",
       "      <td>great gatsby</td>\n",
       "      <td>f scott fitzgerald</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Author  Year  \\\n",
       "0               Suzanne Collins  2008   \n",
       "1  J.K. Rowling, Mary GrandPrÃ©  1997   \n",
       "2               Stephenie Meyer  2005   \n",
       "3                    Harper Lee  1960   \n",
       "4           F. Scott Fitzgerald  1925   \n",
       "\n",
       "                                      Title  Mean Rating  \\\n",
       "0                          The Hunger Games            4   \n",
       "1  Harry Potter and the Philosopher's Stone            4   \n",
       "2                                  Twilight            3   \n",
       "3                     To Kill a Mockingbird            4   \n",
       "4                          The Great Gatsby            4   \n",
       "\n",
       "                    cleaned_title           cleaned_author  \n",
       "0                     hunger game          suzanne collins  \n",
       "1  harry potter philosopher stone  jk rowling mary grandpr  \n",
       "2                        twilight          stephenie meyer  \n",
       "3                kill mockingbird               harper lee  \n",
       "4                    great gatsby       f scott fitzgerald  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.drop(columns=newgbxcolumns_to_copy, inplace=True)\n",
    "gbx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb Cell 79\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb#Y365sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdill\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb#Y365sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dill\u001b[39m.\u001b[39;49mdump_session(\u001b[39m'\u001b[39;49m\u001b[39mnotebook_env.db\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/session.py:267\u001b[0m, in \u001b[0;36mdump_session\u001b[0;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump_session\u001b[39m(filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, main\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, byref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    266\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mdump_session() has been renamed dump_module()\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mPendingDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 267\u001b[0m     dump_module(filename, module\u001b[39m=\u001b[39;49mmain, refimported\u001b[39m=\u001b[39;49mbyref, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/session.py:258\u001b[0m, in \u001b[0;36mdump_module\u001b[0;34m(filename, module, refimported, **kwds)\u001b[0m\n\u001b[1;32m    256\u001b[0m     pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     pickler\u001b[39m.\u001b[39m_main_modified \u001b[39m=\u001b[39m main \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m pickler\u001b[39m.\u001b[39m_original_main\n\u001b[0;32m--> 258\u001b[0m     pickler\u001b[39m.\u001b[39;49mdump(main)\n\u001b[1;32m    259\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:  \u001b[39m# if newly opened file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:420\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(\u001b[39mself\u001b[39m, obj): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     logger\u001b[39m.\u001b[39mtrace_setup(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 420\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:1688\u001b[0m, in \u001b[0;36msave_module\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(main_dict\u001b[39m.\u001b[39mget(item), \u001b[39m'\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mIPython\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1687\u001b[0m             \u001b[39mdel\u001b[39;00m main_dict[item]\n\u001b[0;32m-> 1688\u001b[0m     pickler\u001b[39m.\u001b[39;49msave_reduce(_import_module, (mod_name,), obj\u001b[39m=\u001b[39;49mobj, state\u001b[39m=\u001b[39;49mmain_dict)\n\u001b[1;32m   1689\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# M1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1690\u001b[0m \u001b[39melif\u001b[39;00m obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdill._dill\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1215\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1218\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1215\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1218\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     save(func)\n\u001b[0;32m--> 692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 886\u001b[0m         save(element)\n\u001b[1;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    899\u001b[0m write(MARK)\n\u001b[1;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 901\u001b[0m     save(element)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     save(func)\n\u001b[0;32m--> 692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 886\u001b[0m         save(element)\n\u001b[1;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:406\u001b[0m, in \u001b[0;36mPickler.save.<locals>.save_numpy_array\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    404\u001b[0m npdict \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    405\u001b[0m f, args, state \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m__reduce__()\n\u001b[0;32m--> 406\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(_create_array, (f,args,state,npdict), obj\u001b[39m=\u001b[39;49mobj)\n\u001b[1;32m    407\u001b[0m logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# Nu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     save(func)\n\u001b[0;32m--> 692\u001b[0m     save(args)\n\u001b[1;32m    693\u001b[0m     write(REDUCE)\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    899\u001b[0m write(MARK)\n\u001b[1;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 901\u001b[0m     save(element)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    899\u001b[0m write(MARK)\n\u001b[1;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[0;32m--> 901\u001b[0m     save(element)\n\u001b[1;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:931\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m LIST)\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_appends(obj)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:955\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    953\u001b[0m     write(MARK)\n\u001b[1;32m    954\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m--> 955\u001b[0m         save(x)\n\u001b[1;32m    956\u001b[0m     write(APPENDS)\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:539\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mcommit_frame()\n\u001b[1;32m    538\u001b[0m \u001b[39m# Check for persistent id (defined by a subclass)\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpersistent_id(obj)\n\u001b[1;32m    540\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m save_persistent_id:\n\u001b[1;32m    541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_pers(pid)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.18_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pickle.py:605\u001b[0m, in \u001b[0;36m_Pickler.persistent_id\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_reduce(obj\u001b[39m=\u001b[39mobj, \u001b[39m*\u001b[39mrv)\n\u001b[0;32m--> 605\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpersistent_id\u001b[39m(\u001b[39mself\u001b[39m, obj):\n\u001b[1;32m    606\u001b[0m     \u001b[39m# This exists so a subclass can override it\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_pers\u001b[39m(\u001b[39mself\u001b[39m, pid):\n\u001b[1;32m    610\u001b[0m     \u001b[39m# Save a persistent id reference\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py:326\u001b[0m, in \u001b[0;36mThreadTracer.__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args \u001b[39m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[39m# ENDIF\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, frame, event, arg):\n\u001b[1;32m    327\u001b[0m \u001b[39m        \u001b[39m\u001b[39m''' This is the callback used when we enter some context in the debugger.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[1;32m    329\u001b[0m \u001b[39m        We also decorate the thread we are in with info about the debugging.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m            This is the global debugger (this method should actually be added as a method to it).\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m        '''\u001b[39;00m\n\u001b[1;32m    339\u001b[0m         \u001b[39m# IFDEF CYTHON\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         \u001b[39m# cdef str filename;\u001b[39;00m\n\u001b[1;32m    341\u001b[0m         \u001b[39m# cdef str base;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[39m# DEBUG = 'code_to_debug' in frame.f_code.co_filename\u001b[39;00m\n\u001b[1;32m    351\u001b[0m         \u001b[39m# if DEBUG: print('ENTER: trace_dispatch: %s %s %s %s' % (frame.f_code.co_filename, frame.f_lineno, event, frame.f_code.co_name))\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dill \n",
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb Cell 81\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sanjeevani1109/Desktop/Book_Recommendation_System/nour.ipynb#Y400sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dill\u001b[39m.\u001b[39;49mload_session(\u001b[39m'\u001b[39;49m\u001b[39mnotebook_env.db\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/session.py:512\u001b[0m, in \u001b[0;36mload_session\u001b[0;34m(filename, main, **kwds)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_session\u001b[39m(filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, main\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    511\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mload_session() has been renamed load_module().\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mPendingDeprecationWarning\u001b[39;00m)\n\u001b[0;32m--> 512\u001b[0m     load_module(filename, module\u001b[39m=\u001b[39;49mmain, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/session.py:494\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(filename, module, **kwds)\u001b[0m\n\u001b[1;32m    491\u001b[0m         runtime_main \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__runtime__.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m main\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    492\u001b[0m         sys\u001b[39m.\u001b[39mmodules[runtime_main] \u001b[39m=\u001b[39m main\n\u001b[0;32m--> 494\u001b[0m     loaded \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    495\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# if newly opened file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/dill/_dill.py:444\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     obj \u001b[39m=\u001b[39m StockUnpickler\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39mgetattr\u001b[39m(_main_module, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    446\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore:\n\u001b[1;32m    447\u001b[0m             \u001b[39m# point obj class to main\u001b[39;00m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sanjeevani1109/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Ensure nltk data is downloaded (stopwords, punkt, wordnet)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_tfidf(df):\n",
    "    # Combine title and author after cleaning for more context\n",
    "    df['combined'] = df['cleaned_title'] + \" \" + df['cleaned_author']\n",
    "    # df['combined'] = df['combined'].apply(clean_text)\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined'])\n",
    "    return tfidf_matrix, tfidf_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>3</td>\n",
       "      <td>harry potter philosopher stone</td>\n",
       "      <td>jk rowling mary grandpr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>4</td>\n",
       "      <td>kill mockingbird</td>\n",
       "      <td>harper lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>4</td>\n",
       "      <td>great gatsby</td>\n",
       "      <td>f scott fitzgerald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>The Hobbit or There and Back Again</td>\n",
       "      <td>4</td>\n",
       "      <td>hobbit back</td>\n",
       "      <td>jrr tolkien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J.D. Salinger</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>The Catcher in the Rye</td>\n",
       "      <td>4</td>\n",
       "      <td>catcher rye</td>\n",
       "      <td>jd salinger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Author    Year  \\\n",
       "0  J.K. Rowling, Mary GrandPrÃ©  1997.0   \n",
       "1                    Harper Lee  1960.0   \n",
       "2           F. Scott Fitzgerald  1925.0   \n",
       "3                J.R.R. Tolkien  1937.0   \n",
       "4                 J.D. Salinger  1951.0   \n",
       "\n",
       "                                      Title  Mean Rating  \\\n",
       "0  Harry Potter and the Philosopher's Stone            3   \n",
       "1                     To Kill a Mockingbird            4   \n",
       "2                          The Great Gatsby            4   \n",
       "3        The Hobbit or There and Back Again            4   \n",
       "4                    The Catcher in the Rye            4   \n",
       "\n",
       "                    cleaned_title           cleaned_author  \n",
       "0  harry potter philosopher stone  jk rowling mary grandpr  \n",
       "1                kill mockingbird               harper lee  \n",
       "2                    great gatsby       f scott fitzgerald  \n",
       "3                     hobbit back              jrr tolkien  \n",
       "4                     catcher rye              jd salinger  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Harry Potter and the Philosopher's Stone                                                            1\n",
       "The Fourth Hand                                                                                     1\n",
       "Rachael Ray 365: No Repeats--A Year of Deliciously Different Dinners (A 30-Minute Meal Cookbook)    1\n",
       "á½ÏÎ­ÏÏÎµÎ¹Î±                                                                                   1\n",
       "Manual do guerreiro da luz                                                                          1\n",
       "                                                                                                   ..\n",
       "The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory        1\n",
       "Seven Up                                                                                            1\n",
       "Hard Eight                                                                                          1\n",
       "What Is the What: The Autobiography of Valentino Achak Deng                                         1\n",
       "The First World War                                                                                 1\n",
       "Name: count, Length: 794, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Scaled Rating</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>cleaned_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>classical mythology</td>\n",
       "      <td>mark p morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>decision normandy</td>\n",
       "      <td>carlo deste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>flu story great influenza pandemic search viru...</td>\n",
       "      <td>gina bari kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>mummy urumchi</td>\n",
       "      <td>e j w barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                Author  \\\n",
       "0                                Classical Mythology    Mark P. O. Morford   \n",
       "1                                       Clara Callan  Richard Bruce Wright   \n",
       "2                               Decision in Normandy          Carlo D'Este   \n",
       "3  Flu: The Story of the Great Influenza Pandemic...      Gina Bari Kolata   \n",
       "4                             The Mummies of Urumchi       E. J. W. Barber   \n",
       "\n",
       "   Year  Scaled Rating                                      cleaned_title  \\\n",
       "0  2002              1                                classical mythology   \n",
       "1  2001              3                                       clara callan   \n",
       "2  1991              3                                  decision normandy   \n",
       "3  1999              3  flu story great influenza pandemic search viru...   \n",
       "4  1999              1                                      mummy urumchi   \n",
       "\n",
       "         cleaned_author  \n",
       "0        mark p morford  \n",
       "1  richard bruce wright  \n",
       "2           carlo deste  \n",
       "3      gina bari kolata  \n",
       "4          e j w barber  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_recommendations(df, query, top_k=5, similarity_threshold=0.1):\n",
    "\n",
    "    tfidf_matrix, tfidf_vectorizer = prepare_tfidf(df)\n",
    "    \n",
    "    #transforming the cleaned query to match TF-IDF dimensions\n",
    "    query_vector = tfidf_vectorizer.transform([clean_text(query)])\n",
    "    \n",
    "    #computing cosine similarity\n",
    "    cosine_sim = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sorting items based on similarity scores, but only consider those above the threshold\n",
    "    above_threshold_indices = np.where(cosine_sim >= similarity_threshold)[0]\n",
    "\n",
    "    top_indices = np.argsort(cosine_sim[above_threshold_indices]) # Fetch more items for diversity\n",
    "    \n",
    "    #times 2 for safety factor\n",
    "    random_selection = random.choices(top_indices, k=(len(top_indices) % top_k**2))\n",
    "    \n",
    "    # #fetching top indices \n",
    "    # top_indices = np.argsort(cosine_sim)[-top_k*10:]  #fetch more items for diversity (*10)\n",
    "    \n",
    "    seen = set()\n",
    "    unique_recommendations = []\n",
    "    # Reverse because when we sort we get smallest to largest\n",
    "    print(len(random_selection))\n",
    "    for index in random_selection:\n",
    "        actual_index = above_threshold_indices[index]\n",
    "        title_author = (df.iloc[actual_index]['Title'].lower(), df.iloc[actual_index]['Author'].lower(), df.iloc[actual_index]['Year'])\n",
    "\n",
    "        same_as_query = df.iloc[actual_index]['Title'].lower() == query.lower()            \n",
    "\n",
    "        if title_author not in seen and not same_as_query:\n",
    "            seen.add(title_author)\n",
    "            unique_recommendations.append(actual_index)\n",
    "\n",
    "        # Continue adding until we truly have top_k unique or exhaust the list\n",
    "        if len(unique_recommendations) == top_k or len(seen) == len(top_indices):\n",
    "            break\n",
    "\n",
    "        # if len(unique_recommendations) == top_k:\n",
    "        #     break\n",
    "    \n",
    "    recommendations = df.iloc[unique_recommendations][['Title', 'Author', 'Year']]\n",
    "    return recommendations  # Return recommendations in descending order of similarity\n",
    "    # return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "                                                  Title          Author  Year\n",
      "8374                                    True Love Story    Willow Aster  2013\n",
      "4008                                     Love, Stargirl  Jerry Spinelli  2007\n",
      "6269                              Love in the Afternoon    Lisa Kleypas  2010\n",
      "4873                                          Love wins        Rob Bell  2011\n",
      "196   Marley & Me: Life and Love with the World's Wo...     John Grogan  2005\n"
     ]
    }
   ],
   "source": [
    "# df_to_use should be either your bx or gbx DataFrame\n",
    "# Ensure 'Title' and 'Author' columns are present\n",
    "query_title = \"Love\"\n",
    "recommended_titles = generate_recommendations(gbx, query_title, top_k=5)\n",
    "print(recommended_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270151, 7)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 7)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbx[gbx['Title'].str.contains(\"Harry Potter\", case=False)]\n",
    "gbx[gbx['Title'].str.contains(\"Harry Potter\")]['Title'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbx[gbx['Author'].str.contains(\"Dan Brown\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx[bx['Title'].str.contains(\"Harry Potter\")]['Title'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
